{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Midterm Assignment draft (NOT FINALIZED)\n",
    "\n",
    "Please fill in blanks in the *Answer* sections of this notebook. To check your answer for a problem, run the Setup, Answer, and Result sections. DO NOT MODIFY SETUP OR RESULT CELLS. See the [README](https://github.com/mortonne/datascipsych) for instructions on setting up a Python environment to run this notebook.\n",
    "\n",
    "Write your answers for each problem. Then restart the kernel, run all cells, and then save the notebook. Upload your notebook to Canvas.\n",
    "\n",
    "If you get stuck, read through the other notebooks in this directory, ask us for help in class, or ask other students for help in class or on the weekly discussion board."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem: variables (2 points)\n",
    "Create a variable called `participant_id` with the value `\"001\"`, a variable called `age` with the value `23`, a variable called `score` with the value `4.9`, and a variable called `excluded` with the value `False`. Use these variables in an f-string to create a variable called `summary` with this string: `\"001: age 23; score 4.9; excluded: False\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_id = None\n",
    "age = None\n",
    "score = None\n",
    "excluded = None\n",
    "summary = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = [participant_id, age, score, excluded, summary]\n",
    "if all([v is not None for v in vars]):\n",
    "    # this should print your variables\n",
    "    print(participant_id, age, score, excluded)\n",
    "    print(summary)\n",
    "\n",
    "    # this should not throw any errors\n",
    "    assert summary == \"001: age 23; score 4.9; excluded: False\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem: working with dictionaries (2 points)\n",
    "\n",
    "Often, it is helpful to have multiple variables organized together for a set of participants. One way to do this is using a dictionary. Each key in the dictionary will correspond to a list of data.\n",
    "\n",
    "Create a dictionary called `data` with these keys: `\"participant_id\"`, `\"age\"`, `\"score\"`. `\"excluded\"`.\n",
    "\n",
    "The `\"participant_id\"` key should have a list with the strings `\"001\"`, `\"002\"`.\n",
    "\n",
    "The `\"age\"` key should have a list with the integers `23`, `28`.\n",
    "\n",
    "The `\"score\"` key should have a list with the floats `4.9`, `5.3`.\n",
    "\n",
    "The `\"excluded\"` key should have a list with the boolean values `False`, `True`.\n",
    "\n",
    "Use indexing to access your dictionary and get the age of the second participant in a variable called `age_002`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = None\n",
    "age_002 = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = [data]\n",
    "if all([v is not None for v in vars]):\n",
    "    # this should print your variables\n",
    "    print(data)\n",
    "\n",
    "    # this should not throw any errors\n",
    "    keys = [\"participant_id\", \"age\", \"score\", \"excluded\"]\n",
    "    assert all(k in data for k in keys)\n",
    "    assert data[\"participant_id\"][0] == \"001\"\n",
    "    assert data[\"age\"][0] == 23\n",
    "    assert data[\"score\"][0] == 4.9\n",
    "    assert data[\"excluded\"][0] == False\n",
    "    assert age_002 == 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem: working with lists (2 points)\n",
    "In psychology studies, often participants will be assigned a number (for example, 1 or 2). This number may then be placed into a string indicating a full identifier (for example, \"sub-1\" or \"sub-2\").\n",
    "\n",
    "Create a list called `participant_numbers` with these integer values: `1`, `2`, `3`, `4`. Use a for loop (or list comprehension) to create a list called `participant_ids` with these string values: `\"sub-1\"`, `\"sub-2\"`, `\"sub-3\"`, `\"sub-4\"`. Use slicing to get the last two participant IDs in a list called `last_two_ids`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_numbers = None\n",
    "participant_ids = None\n",
    "last_two_ids = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = [participant_numbers, participant_ids, last_two_ids]\n",
    "if all([v is not None for v in vars]):\n",
    "    # this should print your variables\n",
    "    print(participant_numbers)\n",
    "    print(participant_ids)\n",
    "    print(last_two_ids)\n",
    "\n",
    "    # this should not throw any errors\n",
    "    assert participant_numbers[0] == 1\n",
    "    assert participant_numbers[3] == 4\n",
    "    assert participant_ids == [\"sub-1\", \"sub-2\", \"sub-3\", \"sub-4\"]\n",
    "    assert last_two_ids == [\"sub-3\", \"sub-4\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem: data analysis using arrays (2 points)\n",
    "Say that there was a study where participants were asked to make a series of responses as quickly and accurately as they could. We want to know how accurate fast and slow responses were. One way to divide up responses is using a *median split*, where responses are divided up by whether they are faster or slower than the median.\n",
    "\n",
    "Calculate the median response time over all trials based on the `response_time` array defined below. Then calculate the mean accuracy (based on the `correct` array defined below) for fast trials (that is, trials with a shorter response time than the median) and slow trials (that is, trials with a longer response time than the median) separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "correct = np.array([0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0])\n",
    "response_time = np.array([3.4, 2.5, 3.6, 2.4, 1.8, 1.9, 2.3, 2.0, 3.4, 2.8, 4.5, 5.1, 4.2, 4.4, 5.5, 2.3])\n",
    "rt_median = None\n",
    "accuracy_fast = None\n",
    "accuracy_slow = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = [rt_median, accuracy_fast, accuracy_slow]\n",
    "if all([v is not None for v in vars]):\n",
    "    # this should print your variables\n",
    "    print(rt_median, accuracy_fast, accuracy_slow)\n",
    "\n",
    "    # this should not throw any errors\n",
    "    assert round(rt_median, 2) == 3.10\n",
    "    assert accuracy_fast == 0.125\n",
    "    assert accuracy_slow == 0.875"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem: scoring responses (2 points)\n",
    "In some studies, participants are asked to detect some sort of target. For example, someone might be shown a series of words and asked if each word is \"old\" (that is, one that they have seen before) or \"new\" (that is, a word that they didn't see during the study). Words that were actually shown before are called \"targets\" and words that were not shown before are called \"lures\". There are two kinds of responses that we are usually interested in: hits (target words where the participant responded \"old\") and false alarms (lure words where the participant responded \"new\").\n",
    "\n",
    "Create a function called `score_responses` that takes `trial_type` and `response` variables, and returns two variables with the number of hits and the number of false alarms.\n",
    "\n",
    "`trial_type` is an array that indicates whether each trial was a `\"target\"` or a `\"lure\"`.\n",
    "\n",
    "`response` is an array that indicates whether the response on each trial was `\"old\"` or `\"new\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "score_responses = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = [score_responses]\n",
    "if all([v is not None for v in vars]):\n",
    "    # this should not throw any errors\n",
    "    trial_type = np.array([\"target\", \"lure\", \"lure\", \"target\", \"lure\", \"target\", \"target\", \"lure\"])\n",
    "    response = np.array([\"old\", \"old\", \"new\", \"old\", \"new\", \"new\", \"old\", \"new\"])\n",
    "    n_hit, n_false_alarm = score_responses(trial_type, response)\n",
    "    assert n_hit == 3\n",
    "    assert n_false_alarm == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem: response times (2 points)\n",
    "Take the array of response times `response_times` in seconds generated below and plot a histogram with bins between 2 seconds and 8 seconds, with one bin for each 0.5 seconds (the first bin should by 3.0-3.5 s, the second bin should be 3.5-4.0 s, etc.).\n",
    "\n",
    "Also use NumPy functions to calculate the mean (in a variable called `rt_mean`) and standard deviation (in a variable called `rt_sd`) of the response times, with missing data (indicated by `NaN`) excluded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# generate some random response times\n",
    "response_times = stats.exponnorm.rvs(3, loc=4, scale=.2, size=500, random_state=42)\n",
    "\n",
    "# include some missing samples\n",
    "missing = np.array([15, 105, 230, 400])\n",
    "response_times[missing] = np.nan\n",
    "\n",
    "# variables to set\n",
    "rt_mean = None\n",
    "rt_sd = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here; this should display a histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = [rt_mean, rt_sd]\n",
    "if all([v is not None for v in vars]):\n",
    "    # this should print your variables\n",
    "    print(rt_mean, rt_sd)\n",
    "\n",
    "    # this should not throw any errors\n",
    "    assert round(rt_mean, 2) == 4.61\n",
    "    assert round(rt_sd, 2) == 0.62"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem (graduate students): central tendency (4 points)\n",
    "We talked about two measures of central tendency, the mean and the median. We also talked about dealing with missing data, as represented by `NaN` values.\n",
    "\n",
    "Write a function called `central_tendency` that calculates measures of central tendency. It should take in three inputs: `x`, `measure`, `exclude_nan`, and return the specified measure for the data in `x`.\n",
    "\n",
    "`x` is an array of numbers.\n",
    "\n",
    "`measure` may be either `\"mean\"` or `\"median\"`. The function should raise a `ValueError` with the message `\"Error: unknown measure\"` if some other input is given. \n",
    "\n",
    "`exclude_nan` is either `True` or `False`. If `True`, then the measure should be calculated after excluding `NaN` values. If `False`, then the measure should be calculated based on all values, even if there are `NaN` values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "central_tendency = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = [central_tendency]\n",
    "if all([v is not None for v in vars]):\n",
    "    # this should not throw any errors\n",
    "    x = np.array([5, np.nan, 9, 10, 1, 2, 3, 22])\n",
    "    assert round(central_tendency(x, \"mean\", True), 2) == 7.43\n",
    "    assert central_tendency(x, \"median\", True) == 5\n",
    "    assert np.isnan(central_tendency(x, \"mean\", False))\n",
    "    assert np.isnan(central_tendency(x, \"median\", False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem (graduate students): simulating behavioral responses (4 points)\n",
    "[Signal detection theory](https://www.cns.nyu.edu/~david/handouts/sdt/sdt.html) is a general framework for simulating detection of a some sort of signal. For example, when deciding if a word has been previously seen before, people may use some sort of memory strength signal, which tends to be stronger for previously seen words. In this model, people will say \"old\" to indicate that a word has been seen before if the strength exceeds some threshold or *criterion*, and otherwise they will say \"new\" indicate that the word has not been seen before.\n",
    "\n",
    "Use NumPy to simulate 500 target trials and 500 lure trials, using `np.random.default_rng` with a seed of 42. The target memory strengths should be sampled from a normal distribution with a mean of 1 and a standard deviation of 0.5. The lure memory strength distribution should have a mean of 0 and a standard deviation of 0.5. Test two criterion values; criterion 1 will be 0.5, and criterion 2 will be 0.8. Increasing the criterion will reduce false alarms, but will also lower the hit rate.\n",
    "\n",
    "Randomly generate memory strength for 500 targets and 500 lures, and compare them to the criterion to determine what the behavioral response will be. In the simulation, any trial with strength greater than or equal to the criterion will generate the response \"old\", and any trial with strength less than the criterion will generate the response \"new\". Calculate hit rate and false alarm rate in your simulation, for each of the two criterion values.\n",
    "\n",
    "![Internal response probability of occurrence curves for noise-alone and signal-plus-noise trials. Since the curves overlap, the internal response for a noise-alone trial may exceed the internal response for a signal-plus-noise trial. Vertical lines correspond to the criterion response.](sdt.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "lure_strength = None\n",
    "target_strength = None\n",
    "criterion1 = None\n",
    "criterion2 = None\n",
    "hit_rate1 = None\n",
    "false_alarm_rate1 = None\n",
    "hit_rate2 = None\n",
    "false_alarm_rate2 = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = [\n",
    "    lure_strength, \n",
    "    target_strength, \n",
    "    criterion1, \n",
    "    criterion2, \n",
    "    hit_rate1, \n",
    "    false_alarm_rate1, \n",
    "    hit_rate2, \n",
    "    false_alarm_rate2,\n",
    "]\n",
    "if all([v is not None for v in vars]):\n",
    "    # this should make a histogram plotting your distributions\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.hist(lure_strength, alpha=0.8)\n",
    "    plt.hist(target_strength, alpha=0.8)\n",
    "    plt.vlines([criterion1, criterion2], 0, 200)\n",
    "    plt.xlabel(\"Memory strength\")\n",
    "\n",
    "    # this should print your variables\n",
    "    print(hit_rate1, false_alarm_rate1)\n",
    "    print(hit_rate2, false_alarm_rate2)\n",
    "\n",
    "    # this should not throw any errors\n",
    "    assert np.abs(hit_rate1 - 0.816) < 0.05  # check that simulation is close to expected\n",
    "    assert np.abs(false_alarm_rate1 - 0.138) < 0.05\n",
    "    assert np.abs(hit_rate2 - 0.654) < 0.05\n",
    "    assert np.abs(false_alarm_rate2 - 0.054) < 0.05"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascipsych",
   "language": "python",
   "name": "datascipsych"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
